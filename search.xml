<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>python爬虫爬取图片</title>
      <link href="/2023/11/20/python%E7%88%AC%E8%99%AB%E5%9B%BE%E7%89%87/"/>
      <url>/2023/11/20/python%E7%88%AC%E8%99%AB%E5%9B%BE%E7%89%87/</url>
      
        <content type="html"><![CDATA[<h1 id="python爬虫简单基础"><a href="#python爬虫简单基础" class="headerlink" title="python爬虫简单基础"></a>python爬虫简单基础</h1><h2 id="使用Request库"><a href="#使用Request库" class="headerlink" title="使用Request库"></a>使用Request库</h2><p>优点：简单、发送网络请求快</p><p>缺点：容易被反爬策略针对</p><h3 id="request库的使用"><a href="#request库的使用" class="headerlink" title="request库的使用"></a>request库的使用</h3><h4 id="携带Headers去发送网络请求"><a href="#携带Headers去发送网络请求" class="headerlink" title="携带Headers去发送网络请求"></a>携带Headers去发送网络请求</h4><blockquote><p>模拟浏览器环境、欺骗服务器、获取和浏览器一致的内容</p></blockquote><p>比较重要的就是<code>ua</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;<span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">request.get(url,headers=headers)</span><br></pre></td></tr></table></figure><h4 id="发送携带参数的请求"><a href="#发送携带参数的请求" class="headerlink" title="发送携带参数的请求"></a>发送携带参数的请求</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kw = &#123;<span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;yueyun&#x27;</span>,<span class="string">&#x27;age&#x27;</span>:<span class="number">18</span>&#125;</span><br><span class="line">request.get(url,params=kw)</span><br></pre></td></tr></table></figure><blockquote><p>在 url 地址中，很多参数是没有用的，比如百度搜索的 url 地址，其中参数只有一个字段有用，其他的都可以删除</p></blockquote><h4 id="发送post请求"><a href="#发送post请求" class="headerlink" title="发送post请求"></a>发送post请求</h4><ul><li>登录注册</li><li>需要传输大文本内容的时候</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&quot;name&quot;</span>: <span class="string">&quot;yueyun&quot;</span>,</span><br><span class="line">    <span class="string">&quot;age&quot;</span>: <span class="number">18</span></span><br><span class="line">&#125;</span><br><span class="line">response = requests.post(<span class="string">&quot;http://www.baidu.com/&quot;</span>, data = data,headers=headers)</span><br></pre></td></tr></table></figure><h4 id="使用代理"><a href="#使用代理" class="headerlink" title="使用代理"></a>使用代理</h4><p><strong>使用代理原因：</strong></p><ul><li>让服务器以为不是同一个客户端在请求</li><li>隐藏真实地址</li></ul><p><strong>正向代理和反向代理：</strong></p><ul><li>正向代理：即是**”代理服务器”代理了”客户端”，去和”目标服务器”进行交互**，例如<code>VPN</code></li><li>反向代理：代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。例如<code>Nginx</code></li></ul><p><strong>代理使用:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">proxies = &#123; </span><br><span class="line">    <span class="string">&quot;http&quot;</span>: <span class="string">&quot;http://127.0.0.1:7890&quot;</span>, </span><br><span class="line">    <span class="string">&quot;https&quot;</span>: <span class="string">&quot;https://127.0.0.1:7890&quot;</span>, </span><br><span class="line">    &#125;</span><br><span class="line">requests.get(<span class="string">&quot;http://www.baidu.com&quot;</span>,proxies=proxies)</span><br></pre></td></tr></table></figure><h4 id="代理-IP-使用的注意点"><a href="#代理-IP-使用的注意点" class="headerlink" title="代理 IP 使用的注意点"></a>代理 IP 使用的注意点</h4><ul><li><p>反反爬<br>使用代理 ip 是非常必要的一种<code>反反爬</code>的方式，但是即使使用了代理 ip，对方服务器任然会有很多的方式来检测我们是否是一个爬虫</p><ul><li>一段时间内，检测 IP 访问的频率，访问太多频繁会屏蔽</li><li>检查 Cookie，User-Agent，Referer 等 header 参数，若没有则屏蔽</li><li>服务方购买所有代理提供商，加入到反爬虫数据库里，若检测是代理则屏蔽</li></ul><p>所以更好的方式是购买质量更高的代理，或者自己搭建代理服务器，组装自己的<code>代理IP池</code>，同时在使用的时候使用随机的方式进行选择使用，不要每次都用一个代理 ip，没事没有任何效果的</p></li><li><p>代理IP池更新</p></li></ul><h3 id="使用Request处理cookie等相关的请求"><a href="#使用Request处理cookie等相关的请求" class="headerlink" title="使用Request处理cookie等相关的请求"></a>使用Request处理cookie等相关的请求</h3><h4 id="cookie和session的区别"><a href="#cookie和session的区别" class="headerlink" title="cookie和session的区别"></a>cookie和session的区别</h4><ul><li>cookie 数据存放在客户的浏览器上，session 数据放在服务器上。</li><li>cookie 不是很安全，别人可以分析存放在本地的 cookie 并进行 cookie 欺骗。</li><li>session 会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能。</li><li>单个 cookie 保存的数据不能超过 4K，很多浏览器都限制一个站点最多保存 20 个 cookie。</li></ul><h4 id="处理cookie请求方式-session"><a href="#处理cookie请求方式-session" class="headerlink" title="处理cookie请求方式 - session"></a>处理cookie请求方式 - session</h4><ul><li><p>Requests提供了一个叫做<code>session</code>类，来实现客户端和服务端的<code>会话保持</code></p></li><li><p>会话保持有两个内涵：</p><ul><li>保存 cookie</li><li>实现和服务端的长连接</li></ul></li><li><p>使用方法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">session = requests.session()</span><br><span class="line">response = session.get(url,headers)</span><br></pre></td></tr></table></figure><p>session 实例在请求了一个网站后，对方服务器设置在本地的 cookie 会保存在 session 中，下一次再使用 session 请求对方服务器的时候，会带上前一次的 cookie</p></li></ul><h4 id="处理cookie请求方式-headers"><a href="#处理cookie请求方式-headers" class="headerlink" title="处理cookie请求方式 - headers"></a>处理cookie请求方式 - headers</h4><p>headers中的cookie：</p><ul><li>使用分号 (;) 隔开</li><li>分号两边的类似 a&#x3D;b 形式的表示一条 cookie</li><li>a&#x3D;b 中，a 表示键（name），b 表示值（value）</li><li>headers 中仅仅使用了 cookie 的 name 和 value</li></ul><p>cookie 的具体组成的字段</p><p>由于 headers 中对 cookie 仅仅使用它的 name 和 value，所以在代码中我们仅仅需要 cookie 的 name 和 value 即可</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">headers = &#123;</span><br><span class="line"><span class="string">&quot;User-Agent&quot;</span>:<span class="string">&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36&quot;</span>,</span><br><span class="line"><span class="string">&quot;Cookie&quot;</span>:<span class="string">&quot; Pycharm-26c2d973=dbb9b300-2483-478f-9f5a-16ca4580177e; Hm_lvt_98b9d8c2fd6608d564bf2ac2ae642948=1512607763; Pycharm-26c2d974=f645329f-338e-486c-82c2-29e2a0205c74; _xsrf=2|d1a3d8ea|c5b07851cbce048bd5453846445de19d|1522379036&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">requests.get(url,headers=headers)</span><br></pre></td></tr></table></figure><p>cookie 有过期时间，所以直接复制浏览器中的 cookie 可能意味着下一程序继续运行的时候需要替换代码中的 cookie，对应的我们也可以通过一个程序专门来获取 cookie 供其他程序使用；当然也有很多网站的 cookie 过期时间很长，这种情况下，直接复制 cookie 来使用更加简单</p><h4 id="处理cookie请求方式-使用-cookies-参数"><a href="#处理cookie请求方式-使用-cookies-参数" class="headerlink" title="处理cookie请求方式 - 使用 cookies 参数"></a>处理cookie请求方式 - 使用 cookies 参数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cookies = &#123;<span class="string">&quot;cookie的name&quot;</span>:<span class="string">&quot;cookie的value&quot;</span>&#125;</span><br><span class="line">requests.get(url,headers=headers,cookies=cookie_dict&#125;</span><br></pre></td></tr></table></figure><p><code>requests.utils.dict_from_cookiejar</code>: 把 cookiejar 对象转化为字典</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://www.baidu.com&quot;</span></span><br><span class="line">response = requests.get(url)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(response.cookies))</span><br><span class="line"></span><br><span class="line">cookies = requests.utils.dict_from_cookiejar(response.cookies)</span><br><span class="line"><span class="built_in">print</span>(cookies)</span><br></pre></td></tr></table></figure><h3 id="Request常见参数"><a href="#Request常见参数" class="headerlink" title="Request常见参数"></a>Request常见参数</h3><p><strong>ssl证书</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;https://www.12306.cn/mormhweb/&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ssl.CertificateError ...</span></span><br><span class="line"><span class="comment"># 添加false</span></span><br><span class="line">response = requests.get(url,verify=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p><strong>超时参数</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response = requests.get(url,timeout=<span class="number">3</span>)</span><br></pre></td></tr></table></figure><p><strong>retrying 模块的使用</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># parse.py</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> retrying <span class="keyword">import</span> retry</span><br><span class="line"></span><br><span class="line">headers = &#123;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@retry(<span class="params">stop_max_attempt_number=<span class="number">3</span></span>) </span><span class="comment">#最大重试3次，3次全部报错，才会报错</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_parse_url</span>(<span class="params">url</span>)</span><br><span class="line">    response = requests.get(url, headers=headers, timeout=<span class="number">3</span>) <span class="comment">#超时的时候回报错并重试</span></span><br><span class="line">    <span class="keyword">assert</span> response.status_code == <span class="number">200</span> <span class="comment">#状态码不是200，也会报错并充实</span></span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_url</span>(<span class="params">url</span>)</span><br><span class="line">    <span class="keyword">try</span>: <span class="comment">#进行异常捕获</span></span><br><span class="line">        response = _parse_url(url)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        response = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">return</span> response</span><br></pre></td></tr></table></figure><h2 id="使用无头浏览器selenium"><a href="#使用无头浏览器selenium" class="headerlink" title="使用无头浏览器selenium"></a>使用无头浏览器selenium</h2><p>… </p><h2 id="数据提取"><a href="#数据提取" class="headerlink" title="数据提取"></a>数据提取</h2><p>… </p><h1 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h1><p>爬取 <strong><a href="https://www.vilipix.com/">vilipix</a>上面的图片</strong></p><p>需要使用到的依赖:</p><ul><li><code>pip install requests</code></li><li><code>pip install pyquery</code></li><li><code>pip install fake-useragent</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> pyquery <span class="keyword">import</span> PyQuery <span class="keyword">as</span> pq</span><br><span class="line"><span class="keyword">from</span> fake_useragent <span class="keyword">import</span> UserAgent</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urljoin</span><br><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ThreadPoolExecutor</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机请求头</span></span><br><span class="line">ua = UserAgent(verify_ssl=<span class="literal">False</span>, path=<span class="string">&#x27;./fake_useragent0.1.11.json&#x27;</span>)</span><br><span class="line"><span class="comment"># 网站url</span></span><br><span class="line">base_url = <span class="string">&#x27;https://www.vilipix.com&#x27;</span></span><br><span class="line"><span class="comment"># 获取当前日期</span></span><br><span class="line">today = datetime.date.today()</span><br><span class="line"><span class="comment"># 获取昨天的日期，并用于构建url</span></span><br><span class="line">today_str = (datetime.date.today() + datetime.timedelta(days=-<span class="number">1</span>)).strftime(<span class="string">&#x27;%Y%m%d&#x27;</span>)</span><br><span class="line"></span><br><span class="line">mark = <span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;请选择要下载的榜单\n0---每日榜单\n1---每周榜单\n2---每月榜单\n&quot;</span>))</span><br><span class="line">mode = <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">if</span> (mark == <span class="number">0</span>):</span><br><span class="line">    mode = <span class="string">&#x27;daily&#x27;</span></span><br><span class="line"><span class="keyword">elif</span> mark == <span class="number">1</span>:</span><br><span class="line">    mode = <span class="string">&#x27;weekly&#x27;</span></span><br><span class="line"><span class="keyword">elif</span> mark == <span class="number">2</span>:</span><br><span class="line">    mode = <span class="string">&#x27;monthly&#x27;</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;输入有误，即将退出程序&quot;</span>)</span><br><span class="line">    os._exit(<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 分布创建属于榜单的文件夹(可以自定义更改)</span></span><br><span class="line">path_1 = <span class="string">f&#x27;D:/vilipix<span class="subst">&#123;mode&#125;</span>榜单&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path_1):</span><br><span class="line">    os.mkdir(path_1)</span><br><span class="line"></span><br><span class="line">path_2 = <span class="string">f&#x27;D:/vilipix<span class="subst">&#123;mode&#125;</span>榜单/<span class="subst">&#123;today&#125;</span>/&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path_2):</span><br><span class="line">    os.mkdir(path_2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机请求头防止被封</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ua_random</span>():</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">&#x27;use_agent&#x27;</span>: ua.random</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> headers</span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回网页内容</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">scrap_page</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url=url, headers=ua_random())</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            response.encoding = <span class="string">&#x27;utf-8&#x27;</span></span><br><span class="line">            <span class="keyword">return</span> response.text</span><br><span class="line">    <span class="keyword">except</span> requests.RequestException:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;url&#125;</span>不可爬取！&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 返回具体的url地址</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">scrap_index</span>(<span class="params">page</span>):</span><br><span class="line">    url = <span class="string">f&#x27;<span class="subst">&#123;base_url&#125;</span>/ranking?date=<span class="subst">&#123;today_str&#125;</span>&amp;mode=<span class="subst">&#123;mode&#125;</span>&amp;p=<span class="subst">&#123;page&#125;</span>&#x27;</span></span><br><span class="line">    <span class="keyword">return</span> scrap_page(url)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对页面进行解析</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_index</span>(<span class="params">html</span>):</span><br><span class="line">    doc = pq(html)</span><br><span class="line">    <span class="comment"># pQuery 和 web开发中jQuery 差不多 CSS选择器</span></span><br><span class="line">    links = doc(<span class="string">&#x27;#__layout .illust-content li .illust a&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> links.items():</span><br><span class="line">        <span class="comment"># 获取link标签的href属性</span></span><br><span class="line">        href = link.attr(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">        name = href.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]  <span class="comment"># 详情页名字，由图片id构成，以防重名</span></span><br><span class="line">        <span class="comment"># 详情页url 拼接</span></span><br><span class="line">        detail_url = urljoin(base_url, href)</span><br><span class="line">        page_count = link(<span class="string">&#x27;.page-count span&#x27;</span>).text()</span><br><span class="line">        <span class="comment"># 惰性生成器</span></span><br><span class="line">        <span class="keyword">yield</span> detail_url, page_count, name</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载图片 保存至本地文件</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">download</span>(<span class="params">path, name, image</span>):</span><br><span class="line">    save_path = path + name + <span class="string">&#x27;.jpg&#x27;</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(save_path, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(image)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 详情页内仅有一张图片时调用</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">detail_index_1</span>(<span class="params">html, name, path</span>):</span><br><span class="line">    doc = pq(html)</span><br><span class="line">    link = doc(<span class="string">&#x27;.illust-pages li a img&#x27;</span>).attr(<span class="string">&#x27;src&#x27;</span>)</span><br><span class="line">    image = requests.get(url=link, headers=ua_random()).content</span><br><span class="line">    download(path, name, image)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 详情页内有超过一张图片时调用</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">detail_index_more</span>(<span class="params">html, name, path</span>):</span><br><span class="line">    doc = pq(html)</span><br><span class="line">    links = doc(<span class="string">&#x27;.illust-pages li a img&#x27;</span>)</span><br><span class="line">    i = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> links.items():</span><br><span class="line">        src = link.attr(<span class="string">&#x27;src&#x27;</span>)</span><br><span class="line">        image_name = name + <span class="string">f&#x27;_<span class="subst">&#123;i&#125;</span>&#x27;</span></span><br><span class="line">        image = requests.get(url=src, headers=ua_random()).content</span><br><span class="line">        download(path, image_name, image)</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载程序入口</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">page</span>):</span><br><span class="line">    html = scrap_index(page)</span><br><span class="line">    details = parse_index(html)</span><br><span class="line">    <span class="keyword">for</span> detail <span class="keyword">in</span> details:</span><br><span class="line">        detail_url = detail[<span class="number">0</span>]  <span class="comment"># 详情页的url</span></span><br><span class="line">        num = detail[<span class="number">1</span>]  <span class="comment"># 详情页内图片的数量</span></span><br><span class="line">        name = detail[<span class="number">2</span>]  <span class="comment"># 给详情页命的名</span></span><br><span class="line">        detail_html = scrap_page(detail_url)</span><br><span class="line">        <span class="keyword">if</span> num == <span class="string">&#x27;1&#x27;</span>:  <span class="comment"># 第①种情况</span></span><br><span class="line">            detail_index_1(detail_html, name, path_2)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># 第②种情况</span></span><br><span class="line">            path_3 = <span class="string">f&#x27;D:/vilipix<span class="subst">&#123;mode&#125;</span>榜单/<span class="subst">&#123;today&#125;</span>/<span class="subst">&#123;name&#125;</span>/&#x27;</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(path_3):</span><br><span class="line">                os.mkdir(path_3)</span><br><span class="line">            detail_index_more(detail_html, name, path_3)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;*&#x27;</span>*<span class="number">10</span>, <span class="string">f&#x27;<span class="subst">&#123;name&#125;</span>下载完毕！&#x27;</span>, <span class="string">&#x27;*&#x27;</span>*<span class="number">10</span>)</span><br><span class="line">    <span class="comment"># print(&quot;图片下载完成辣，谢谢使用！！&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 主程序入口</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    pages = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">15</span>))</span><br><span class="line">    <span class="comment"># 使用多线程进行加速</span></span><br><span class="line">    <span class="keyword">with</span> ThreadPoolExecutor(max_workers=<span class="number">5</span>) <span class="keyword">as</span> executor:</span><br><span class="line">        executor.<span class="built_in">map</span>(main, pages)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;图片下载完成辣，谢谢使用！！&quot;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 爬虫 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> python </tag>
            
            <tag> 爬虫 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux服务器配置代理</title>
      <link href="/2023/11/20/Linux%E4%BB%A3%E7%90%86/"/>
      <url>/2023/11/20/Linux%E4%BB%A3%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux下使用Clash科学上网"><a href="#Linux下使用Clash科学上网" class="headerlink" title="Linux下使用Clash科学上网"></a>Linux下使用Clash科学上网</h1><blockquote><p>在 Linux 服务器上通过 Clash 科学上网<br>如果出现权限不足的情况请在指令前面加上 <code>sudo</code> </p></blockquote><h2 id="安装Clash"><a href="#安装Clash" class="headerlink" title="安装Clash"></a><strong>安装<code>Clash</code></strong></h2><ul><li><p>下载当前操作系统与 CPU 架构对应的包文件，我这儿是 X86_64 平台下的Ubuntu所以对应使用的是<a href="https://github.com/Dreamacro/clash/releases/download/v1.6.5/clash-linux-amd64-v1.6.5.gz">clash-linux-amd64-v1.6.5.gz</a>即ok(当然取github上面找到不同的安装包只要能够对应也ok)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget -O clash.gz https://github.com/Dreamacro/clash/releases/download/v1.6.5/clash-linux-amd64-v1.6.5.gz</span><br></pre></td></tr></table></figure></li><li><p>下载好后解压安装包中 clash 到 <code>/usr/local/bin/</code> 目录下，并删除压缩包文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gzip -dc clash.gz &gt; /usr/local/bin/clash</span><br><span class="line">chmod +x /usr/local/bin/clash</span><br><span class="line">rm -f clash.gz</span><br></pre></td></tr></table></figure></li><li><p>创建配置文件目录，并下载 MMDB 文件(注意这一步很可能失败建议直接在网上找Country.mmdb文件下载并手动上传比较好) <a href="https://github.com/Dreamacro/maxmind-geoip/releases">下载网址</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir /etc/clash</span><br><span class="line">wget -O /etc/clash/Country.mmdb https://www.sub-speeder.com/client-download/Country.mmdb</span><br></pre></td></tr></table></figure></li><li><p>创建 <code>systemd</code> 脚本，脚本文件路径为 <code>/etc/systemd/system/clash.service</code>，内容如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=clash daemon</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=simple</span><br><span class="line">User=root</span><br><span class="line">ExecStart=/usr/local/bin/clash -d /etc/clash/</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure></li><li><p>重载 systemctl daemon</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br></pre></td></tr></table></figure></li></ul><h2 id="配置代理"><a href="#配置代理" class="headerlink" title="配置代理"></a><strong>配置代理</strong></h2><ul><li><p>导入已有的<code>vpn</code> 链接 (订阅链接啦) </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget -O /etc/clash/config.yaml [你的订阅链接]</span><br></pre></td></tr></table></figure></li><li><p>设置系统代理，添加配置文件 <code>/etc/profile.d/proxy.sh</code> 并在其中写入如下内容：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export http_proxy=&quot;http://127.0.0.1:7890&quot;</span><br><span class="line">export https_proxy=&quot;http://127.0.0.1:7890&quot;</span><br><span class="line">export HTTP_PROXY=&quot;http://127.0.0.1:7890&quot;</span><br><span class="line">export HTTPS_PROXY=&quot;http://127.0.0.1:7890&quot;</span><br></pre></td></tr></table></figure></li><li><p>重载 <code>/etc/profile</code> 配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></li><li><p>启动 <code>clash</code> 服务，并设置为开机自动启</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start clash</span><br><span class="line">systemctl enable clash</span><br></pre></td></tr></table></figure></li><li><p>测试 goolge.com 访问</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">curl google.com</span></span><br><span class="line">&lt;HTML&gt;&lt;HEAD&gt;&lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html;charset=utf-8&quot;&gt;</span><br><span class="line">&lt;TITLE&gt;301 Moved&lt;/TITLE&gt;&lt;/HEAD&gt;&lt;BODY&gt;</span><br><span class="line">&lt;H1&gt;301 Moved&lt;/H1&gt;</span><br><span class="line">The document has moved</span><br><span class="line">&lt;A HREF=&quot;http://www.google.com/&quot;&gt;here&lt;/A&gt;.</span><br><span class="line">&lt;/BODY&gt;&lt;/HTML&gt;</span><br></pre></td></tr></table></figure></li></ul><h2 id="配置web-UI"><a href="#配置web-UI" class="headerlink" title="配置web-UI"></a><strong>配置web-UI</strong></h2><ul><li><p>克隆 <a href="https://github.com/Dreamacro/clash-dashboard">clash-dashboard</a> 项目到本地</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone -b gh-pages --depth 1 https://github.com/Dreamacro/clash-dashboard /opt/clash-dashboard</span><br></pre></td></tr></table></figure></li><li><p>修改 <code>clash</code> 配置文件中 <code>external-ui</code> 的值为 <code>/opt/clash-dashboard</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i &quot;s/^#\&#123;0,1\&#125; \&#123;0,1\&#125;external-ui.*/external-ui: \/opt\/clash-dashboard/&quot; /etc/clash/config.yaml</span><br></pre></td></tr></table></figure></li><li><p>重启clash服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart clash</span><br></pre></td></tr></table></figure></li><li><p>通过浏览器访问 <code>localhost:9090/ui</code>，其中 <code>localhost</code> 替换为 clash 部署服务器的 IP</p></li></ul><h2 id="配置定时更新订阅"><a href="#配置定时更新订阅" class="headerlink" title="配置定时更新订阅"></a>配置定时更新订阅</h2><p>使用如下脚本填写相关配置项目并放入 <code>/etc/cron.weekly</code> 目录下，每周自动更新订阅配置文件即可<br><code>sudo vim /etc/cron.weekly/clash.sh</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/usr/bin/env bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">订阅链接地址</span></span><br><span class="line">SUBSCRIBE=&quot;&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">web-ui存放目录，留空则保持默认不修改</span></span><br><span class="line">WEB_UI=&quot;&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">API 端口，留空则保持默认不修改</span></span><br><span class="line">CONTROLLER_API_PROT=&quot;&quot;</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">API 口令，留空则保持默认不修改</span></span><br><span class="line">SECRET=&quot;&quot;</span><br><span class="line"></span><br><span class="line">CLASH_CONFIG=&quot;/etc/clash/config.yaml&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ -z &quot;$&#123;SUBSCRIBE&#125;&quot; ]; then</span><br><span class="line">    echo &quot;Subscription address cannot be empty&quot;</span><br><span class="line">    exit 1</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">systemctl stop clash</span><br><span class="line"></span><br><span class="line">wget --no-proxy -O $&#123;CLASH_CONFIG&#125; $&#123;SUBSCRIBE&#125;</span><br><span class="line"></span><br><span class="line">if [ -n &quot;$&#123;WEB_UI&#125;&quot; ]; then</span><br><span class="line">sed -i &quot;s?^#\&#123;0,1\&#125; \&#123;0,1\&#125;external-ui.*?external-ui: $&#123;WEB_UI&#125;?&quot; $&#123;CLASH_CONFIG&#125;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">if [ -n &quot;$&#123;CONTROLLER_API_PROT&#125;&quot; ]; then</span><br><span class="line">sed -i &quot;s?^external-controller.*?external-controller: &#x27;0.0.0.0:$&#123;CONTROLLER_API_PROT&#125;&#x27;?&quot; $&#123;CLASH_CONFIG&#125;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">if [ -n &quot;$&#123;SECRET&#125;&quot; ]; then</span><br><span class="line">sed -i &quot;s?^secret.*?secret: &#x27;$&#123;SECRET&#125;&#x27;?&quot; $&#123;CLASH_CONFIG&#125;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">systemctl start clash</span><br></pre></td></tr></table></figure><p>上述脚本写入 <code>/etc/cron.weekly/clash.sh</code> 并配置好相关变量后，保存退出并赋予可执行权限<br><code>chmod 0755 /etc/cron.weekly/clash.sh</code><br>至此，Linux 下 clash 配置完成啦！！</p>]]></content>
      
      
      <categories>
          
          <category> 服务器知识 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Clash </tag>
            
            <tag> 代理 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
